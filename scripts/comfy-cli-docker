#!/usr/bin/env bash
# License: GPLv3
# Credits: Felipe Facundes
# Source: https://github.com/comfyanonymous/ComfyUI
# Tutorial: https://www.youtube.com/watch?v=TLE9NmN_sxw
#           https://youtu.be/xWUddF5oMb0
# Docker version for Python 3.13

# Function to display help menu
show_help() {
    cat << EOF

‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                  COMFY-CLI DOCKER SCRIPT (Python 3.13)           ‚ïë
‚ïë                     Containerized Installation                    ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

DESCRIPTION:
    This script creates and manages a Docker container for ComfyUI CLI
    with Python 3.13, automatic GPU detection, and persistent storage.

USAGE:
    $0 [COMMAND] [OPTIONS]

COMMANDS:
    run         Start ComfyUI CLI in Docker container (default if no command)
    build       Build Docker image with Python 3.13
    shell       Open interactive shell in container
    stop        Stop running container
    logs        View container logs
    clean       Remove container and images (keeps data volume)
    purge       Remove everything including data volume
    status      Check container status
    exec        Execute comfy-cli command in running container
    help        Show this help message

OPTIONS for 'run' command:
    -g, --gpu          Use GPU acceleration (NVIDIA/AMD)
    -p, --port PORT    Map container port to host (default: 8188)
    -n, --name NAME    Container name (default: comfy-cli)
    -v, --volume DIR   Mount host directory as volume
    -nu, --nvidia-universal  Force CUDA 12.6 for NVIDIA (compatibility mode)

EXAMPLES:
    # First time: Run container and install everything
    $0 run --gpu -nu
    
    # After installation: Use comfy-cli commands
    $0 exec launch --background
    $0 exec --help
    $0 exec install some-custom-node
    
    # Mount custom models directory
    $0 run --gpu -nu --volume ./my-models:/app/models
    
    # Check status
    $0 status
    
    # Open shell in running container
    $0 shell

USAGE AFTER INSTALLATION:
    Once the container is set up, use these commands:
    
    ‚Ä¢ Start ComfyUI in background: $0 exec launch --background
    ‚Ä¢ Show comfy-cli help:         $0 exec --help
    ‚Ä¢ Install custom nodes:        $0 exec install <node-name>
    ‚Ä¢ Update ComfyUI:              $0 exec update
    ‚Ä¢ Open shell:                  $0 shell
    ‚Ä¢ View logs:                   $0 logs
    ‚Ä¢ Stop:                        $0 stop

DOCKER IMAGE FEATURES:
    ‚Ä¢ Python 3.13 with latest pip
    ‚Ä¢ Automatic GPU detection and PyTorch installation
    ‚Ä¢ NVIDIA Universal mode (-nu) for CUDA 12.6 compatibility
    ‚Ä¢ Persistent data volume: comfy-cli-data
    ‚Ä¢ CUDA support for NVIDIA GPUs
    ‚Ä¢ ROCm support for AMD GPUs
    ‚Ä¢ XPU support for Intel GPUs
    ‚Ä¢ CPU fallback mode

PYTORCH INSTALLATION MODES:
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Mode             ‚îÇ PyTorch Version                         ‚îÇ
    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
    ‚îÇ NVIDIA (auto)    ‚îÇ Based on driver version detection       ‚îÇ
    ‚îÇ NVIDIA (-nu)     ‚îÇ CUDA 12.6 (torch==2.9.0)                ‚îÇ
    ‚îÇ AMD              ‚îÇ ROCm 6.4                                ‚îÇ
    ‚îÇ Intel            ‚îÇ XPU                                     ‚îÇ
    ‚îÇ CPU              ‚îÇ CPU-only version                        ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

VOLUME STRUCTURE:
    ‚Ä¢ /app/comfy-ui          - ComfyUI installation
    ‚Ä¢ /app/models            - AI models storage
    ‚Ä¢ /app/output            - Generated outputs
    ‚Ä¢ /app/config            - Configuration files

EOF
    exit 0
}

# Default configuration
CONTAINER_NAME="comfy-cli"
IMAGE_NAME="comfy-cli-python3.13"
DATA_VOLUME="comfy-cli-data"
HOST_PORT="8188"
CONTAINER_PORT="8188"
USE_GPU=false
HOST_VOLUME=""
FORCE_CUDA126=false
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
DOCKER_CONTEXT="${SCRIPT_DIR}/docker-context"

# Parse command line arguments
parse_arguments() {
    COMMAND="${1:-run}"
    
    case "$COMMAND" in
        run|build|shell|stop|logs|clean|purge|status|exec|help)
            shift
            ;;
        *)
            COMMAND="run"
            ;;
    esac
    
    while [[ $# -gt 0 ]]; do
        case "$1" in
            -g|--gpu)
                USE_GPU=true
                shift
                ;;
            -nu|--nvidia-universal)
                FORCE_CUDA126=true
                shift
                ;;
            -p|--port)
                HOST_PORT="$2"
                shift 2
                ;;
            -n|--name)
                CONTAINER_NAME="$2"
                shift 2
                ;;
            -v|--volume)
                HOST_VOLUME="$2"
                shift 2
                ;;
            -h|--help)
                show_help
                ;;
            *)
                # For 'exec' command, pass remaining args to comfy-cli
                if [[ "$COMMAND" == "exec" ]]; then
                    COMFY_CLI_ARGS="$@"
                fi
                break
                ;;
        esac
    done
}

# Check if container is running
is_container_running() {
    docker ps --format '{{.Names}}' | grep -q "^${CONTAINER_NAME}$"
}

# Show container status
show_status() {
    echo "üìä ComfyUI Docker Status"
    echo "========================"
    
    # Check if image exists
    if docker image inspect "$IMAGE_NAME" &> /dev/null; then
        echo "‚úÖ Docker image: $IMAGE_NAME"
    else
        echo "‚ö†Ô∏è Docker image: $IMAGE_NAME (not built)"
    fi
    
    # Check if volume exists
    if docker volume inspect "$DATA_VOLUME" &> /dev/null; then
        echo "‚úÖ Data volume: $DATA_VOLUME"
    else
        echo "‚ö†Ô∏è Data volume: $DATA_VOLUME (not created)"
    fi
    
    # Check container status
    if is_container_running; then
        echo "‚úÖ Container: $CONTAINER_NAME (RUNNING)"
        echo "   Port: $HOST_PORT ‚Üí $CONTAINER_PORT"
        echo "   Status: $(docker ps --filter "name=$CONTAINER_NAME" --format "{{.Status}}")"
        echo ""
        echo "üåê Access ComfyUI at: http://localhost:$HOST_PORT"
        echo ""
        echo "üöÄ Available commands:"
        echo "   $0 exec launch --background    # Start ComfyUI"
        echo "   $0 shell                       # Open shell"
        echo "   $0 logs                        # View logs"
        echo "   $0 exec --help                 # Show comfy-cli help"
        echo "   $0 stop                        # Stop container"
    elif docker ps -a --format '{{.Names}}' | grep -q "^${CONTAINER_NAME}$"; then
        echo "‚è∏Ô∏è  Container: $CONTAINER_NAME (STOPPED)"
        echo ""
        echo "üí° Start it with: $0 run --gpu"
    else
        echo "‚ùå Container: $CONTAINER_NAME (NOT CREATED)"
        echo ""
        echo "üí° Create it with: $0 run --gpu -nu"
    fi
}

# Execute comfy-cli command in running container
exec_comfy_cli() {
    if ! is_container_running; then
        echo "‚ùå Container '$CONTAINER_NAME' is not running"
        echo "üí° Start it first with: $0 run --gpu"
        exit 1
    fi
    
    echo "üöÄ Executing: comfy-cli $COMFY_CLI_ARGS"
    echo ""
    docker exec -it "$CONTAINER_NAME" comfy-cli $COMFY_CLI_ARGS
}

# Create Docker context directory
create_docker_context() {
    echo "üìÅ Creating Docker build context..."
    
    # Create directory
    rm -rf "$DOCKER_CONTEXT"
    mkdir -p "$DOCKER_CONTEXT"
    
    # Create Dockerfile
    cat > "$DOCKER_CONTEXT/Dockerfile" << 'EOF'
FROM python:3.13-slim

WORKDIR /app

# Install system dependencies for Debian Trixie/Sid
RUN apt-get update && apt-get install -y \
    wget \
    curl \
    git \
    libglib2.0-0 \
    libsm6 \
    libxext6 \
    libxrender1 \
    libgl1 \
    libgomp1 \
    ocl-icd-libopencl1 \
    clinfo \
    pciutils \
    libglvnd0 \
    libglx0 \
    libegl1 \
    && rm -rf /var/lib/apt/lists/*

# For NVIDIA GPU support in container
RUN apt-get update && apt-get install -y --no-install-recommends \
    pkg-config \
    libxcursor-dev \
    libxrandr-dev \
    libxinerama-dev \
    libxi-dev \
    && rm -rf /var/lib/apt/lists/*

# Create directories for persistence
RUN mkdir -p /app/comfy-ui /app/models /app/output /app/config

# Copy scripts
COPY scripts/ /app/

# Set permissions
RUN chmod +x /app/*.sh

# Set environment variables
ENV PYTHONUNBUFFERED=1
ENV PYTHONDONTWRITEBYTECODE=1
ENV PIP_NO_CACHE_DIR=1
ENV COMFYUI_PATH=/app/comfy-ui
ENV MODEL_PATH=/app/models
ENV OUTPUT_PATH=/app/output
ENV HOST_PORT=8188
ENV CONTAINER_NAME=comfy-cli
ENV FORCE_CUDA126=false
ENV DEBIAN_FRONTEND=noninteractive
ENV INSTALLATION_COMPLETE=false

# Set entrypoint
ENTRYPOINT ["/app/entrypoint.sh"]
CMD []
EOF
    
    # Create scripts directory
    mkdir -p "$DOCKER_CONTEXT/scripts"
    
    # Create detect_gpu.sh
    cat > "$DOCKER_CONTEXT/scripts/detect_gpu.sh" << 'SCRIPT_EOF'
#!/bin/bash

FORCE_CUDA126="${FORCE_CUDA126:-false}"

detect_and_install_pytorch() {
    echo "üîç Detecting GPU hardware..."
    
    # Check for NVIDIA GPU
    if command -v nvidia-smi &> /dev/null && nvidia-smi > /dev/null 2>&1; then
        echo "‚úÖ NVIDIA GPU detected"
        
        # NVIDIA Universal mode (force CUDA 12.6)
        if [ "$FORCE_CUDA126" = "true" ]; then
            echo "üîß Using NVIDIA Universal mode (CUDA 12.6)"
            echo "‚¨áÔ∏è Installing PyTorch 2.9.0 with CUDA 12.6"
            pip install torch==2.9.0 torchvision==0.24.0 torchaudio==2.9.0 \
                --index-url https://download.pytorch.org/whl/cu126
            return
        fi
        
        # Auto-detect CUDA version based on driver
        if command -v nvidia-smi &> /dev/null; then
            DRIVER_VERSION=$(nvidia-smi --query-gpu=driver_version --format=csv,noheader | head -1)
            echo "üìä NVIDIA Driver version: $DRIVER_VERSION"
            
            # Extract major version
            DRIVER_MAJOR=$(echo "$DRIVER_VERSION" | cut -d. -f1)
            
            if [ "$DRIVER_MAJOR" -ge 535 ]; then  # Driver 535+
                echo "‚¨áÔ∏è Installing PyTorch with CUDA 12.6 (latest)"
                pip install torch==2.9.0 torchvision==0.24.0 torchaudio==2.9.0 \
                    --index-url https://download.pytorch.org/whl/cu126
            elif [ "$DRIVER_MAJOR" -ge 525 ]; then  # Driver 525-534
                echo "‚¨áÔ∏è Installing PyTorch with CUDA 11.8"
                pip install torch==2.9.0 torchvision==0.24.0 torchaudio==2.9.0 \
                    --index-url https://download.pytorch.org/whl/cu118
            elif [ "$DRIVER_MAJOR" -ge 470 ]; then  # Driver 470-524
                echo "‚¨áÔ∏è Installing PyTorch with CUDA 11.3"
                pip install torch==2.9.0 torchvision==0.24.0 torchaudio==2.9.0 \
                    --index-url https://download.pytorch.org/whl/cu113
            else
                echo "‚ö†Ô∏è Old NVIDIA driver, using CUDA 12.6 as fallback"
                pip install torch==2.9.0 torchvision==0.24.0 torchaudio==2.9.0 \
                    --index-url https://download.pytorch.org/whl/cu126
            fi
        else
            echo "‚¨áÔ∏è Installing PyTorch with CUDA 12.6 (auto-fallback)"
            pip install torch==2.9.0 torchvision==0.24.0 torchaudio==2.9.0 \
                --index-url https://download.pytorch.org/whl/cu126
        fi
        
    # Check for AMD GPU (ROCm)
    elif [[ -d "/dev/dri" ]] && lspci | grep -i "amd" | grep -i "vga" &> /dev/null; then
        echo "‚úÖ AMD GPU detected (ROCm)"
        echo "‚¨áÔ∏è Installing PyTorch with ROCm 6.4"
        pip install torch==2.9.0 torchvision==0.24.0 torchaudio==2.9.0 \
            --index-url https://download.pytorch.org/whl/rocm6.4
    
    # Check for Intel GPU
    elif lspci | grep -i "intel" | grep -i "vga" &> /dev/null; then
        echo "‚úÖ Intel GPU detected"
        echo "‚¨áÔ∏è Installing PyTorch with XPU"
        pip install torch==2.9.0 torchvision==0.24.0 torchaudio==2.9.0 \
            --index-url https://download.pytorch.org/whl/xpu
    
    else
        echo "‚ö†Ô∏è No GPU detected - installing CPU version"
        pip install torch==2.9.0 torchvision==0.24.0 torchaudio==2.9.0
    fi
}

detect_and_install_pytorch
SCRIPT_EOF
    
    # Create setup_comfy.sh (WITH CACHE CHECK)
    cat > "$DOCKER_CONTEXT/scripts/setup_comfy.sh" << 'SCRIPT_EOF'
#!/bin/bash

# Check if installation is already complete
if [ -f "/app/.installation_complete" ] && [ "$(cat /app/.installation_complete)" = "true" ]; then
    echo "‚úÖ Installation already complete. Skipping setup."
    echo "üìä Installed PyTorch version: $(python -c "import torch; print(torch.__version__)")"
    if command -v nvidia-smi &> /dev/null; then
        echo "üéÆ CUDA available: $(python -c "import torch; print(torch.cuda.is_available())")"
    fi
    exit 0
fi

# Set FORCE_CUDA126 from environment variable
export FORCE_CUDA126="${FORCE_CUDA126:-false}"

echo "üîß Configuration:"
echo "   - FORCE_CUDA126: $FORCE_CUDA126"
echo "   - NVIDIA Universal mode: $( [ "$FORCE_CUDA126" = "true" ] && echo "ENABLED" || echo "DISABLED" )"

# Source GPU detection script
source /app/detect_gpu.sh

echo "üì¶ Installing ComfyUI requirements..."
cd /app/comfy-ui

# Download requirements if not present
if [ ! -f "requirements.txt" ]; then
    echo "‚¨áÔ∏è Downloading ComfyUI requirements..."
    wget -q https://raw.githubusercontent.com/comfyanonymous/ComfyUI/refs/heads/master/requirements.txt || \
    curl -s -o requirements.txt https://raw.githubusercontent.com/comfyanonymous/ComfyUI/refs/heads/master/requirements.txt
fi

# Install requirements
if [ -f "requirements.txt" ]; then
    echo "üì• Installing from requirements.txt..."
    pip install -r requirements.txt
else
    echo "‚ö†Ô∏è requirements.txt not found, installing basic packages..."
fi

# Install comfy-cli
echo "üì¶ Installing comfy-cli..."
pip install comfy-cli

# Install additional useful packages
echo "üì¶ Installing additional packages..."
pip install --upgrade pip
pip install \
    pillow \
    numpy \
    scipy \
    pandas \
    matplotlib \
    opencv-python-headless \
    transformers \
    accelerate \
    safetensors \
    websockets \
    aiohttp \
    torchsde \
    kornia \
    rich

# Mark installation as complete
echo "true" > /app/.installation_complete
chmod 644 /app/.installation_complete

echo "‚úÖ ComfyUI setup complete!"
echo "üìä Installed PyTorch version: $(python -c "import torch; print(torch.__version__)")"
if command -v nvidia-smi &> /dev/null; then
    echo "üéÆ Checking CUDA availability..."
    python -c "
import torch
print(f'CUDA available: {torch.cuda.is_available()}')
if torch.cuda.is_available():
    print(f'CUDA version: {torch.version.cuda}')
    print(f'GPU: {torch.cuda.get_device_name(0)}')
    print(f'GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB')
"
fi
SCRIPT_EOF
    
    # Create entrypoint.sh (OPTIMIZED - doesn't reinstall)
    cat > "$DOCKER_CONTEXT/scripts/entrypoint.sh" << 'SCRIPT_EOF'
#!/bin/bash

# Export environment variables for GPU detection
export FORCE_CUDA126="${FORCE_CUDA126:-false}"

echo "üöÄ ComfyUI Docker Container"
echo "==========================="
echo "Python version: $(python --version)"
echo "FORCE_CUDA126: $FORCE_CUDA126"
echo "Working directory: $(pwd)"
echo ""

# Check for GPU
if command -v nvidia-smi &> /dev/null; then
    echo "‚úÖ NVIDIA GPU detected"
elif [[ -d "/dev/dri" ]]; then
    echo "‚úÖ AMD/Intel GPU available"
else
    echo "‚ÑπÔ∏è  Running in CPU mode"
fi

# Check if ComfyUI is installed
if [ ! -d "/app/comfy-ui" ] || [ ! "$(ls -A /app/comfy-ui)" ]; then
    echo ""
    echo "üîÑ First-time setup: Installing ComfyUI..."
    comfy-cli install /app/comfy-ui --force
fi

# Run setup script (will skip if already installed)
source /app/setup_comfy.sh

echo ""
echo "‚úÖ Environment ready!"
echo "üí° Available commands:"
echo "   ‚Ä¢ comfy-cli launch --background   # Start ComfyUI server"
echo "   ‚Ä¢ comfy-cli --help                # Show all commands"
echo "   ‚Ä¢ python main.py --port 8188      # Run ComfyUI directly"
echo ""
echo "üåê Once started, access at: http://localhost:${HOST_PORT:-8188}"
echo ""

# If no arguments, show help
if [ $# -eq 0 ]; then
    echo "‚ö° To start ComfyUI, run: comfy-cli launch --background"
    echo "üìö For more options: comfy-cli --help"
    echo ""
    # Start bash shell
    exec /bin/bash
else
    # Execute passed command
    echo "‚ö° Executing: $@"
    exec "$@"
fi
SCRIPT_EOF
    
    echo "‚úÖ Docker context created at: $DOCKER_CONTEXT"
}

# Build Docker image with Python 3.13
build_image() {
    echo "üöÄ Building Docker image with Python 3.13..."
    
    # Create Docker context
    create_docker_context
    
    # Build the Docker image
    echo "üî® Building image '$IMAGE_NAME'..."
    if docker build --progress=plain -t "$IMAGE_NAME" "$DOCKER_CONTEXT"; then
        echo "‚úÖ Docker image built successfully: $IMAGE_NAME"
        echo "üì¶ Image includes:"
        echo "   ‚Ä¢ Python 3.13"
        echo "   ‚Ä¢ NVIDIA Universal mode support (-nu flag)"
        echo "   ‚Ä¢ Automatic GPU detection"
        echo "   ‚Ä¢ ComfyUI CLI pre-configured"
        echo "   ‚Ä¢ Installation caching (won't reinstall)"
        
        # Show image details
        echo ""
        echo "üìä Image details:"
        docker images "$IMAGE_NAME"
    else
        echo "‚ùå Failed to build Docker image"
        exit 1
    fi
}

# Build GPU arguments for docker run
build_gpu_args() {
    if [ "$USE_GPU" = true ]; then
        # Check for NVIDIA
        if command -v nvidia-smi &> /dev/null; then
            echo "--gpus all"
        # Check for AMD (simplified detection)
        elif [ -d "/dev/dri" ] && [ -d "/dev/kfd" ]; then
            echo "--device /dev/kfd --device /dev/dri --group-add video"
        # Check for Intel
        elif [ -d "/dev/dri" ]; then
            echo "--device /dev/dri --group-add video"
        else
            echo "‚ö†Ô∏è GPU flag set but no GPU detected, running in CPU mode"
            echo ""
        fi
    else
        echo ""
    fi
}

# Run container (interactive mode - for first-time setup)
run_container() {
    echo "üöÄ Starting ComfyUI container..."
    
    # Check if image exists
    if ! docker image inspect "$IMAGE_NAME" &> /dev/null; then
        echo "‚ö†Ô∏è Image not found. Building first..."
        build_image
    fi
    
    # Build volume mounts
    VOLUME_MOUNTS="-v ${DATA_VOLUME}:/app"
    
    if [ -n "$HOST_VOLUME" ]; then
        if [ -d "$HOST_VOLUME" ]; then
            VOLUME_MOUNTS="$VOLUME_MOUNTS -v $(realpath "$HOST_VOLUME"):/app/shared"
            echo "üìÇ Mounting host directory: $HOST_VOLUME ‚Üí /app/shared"
        else
            echo "‚ö†Ô∏è Host volume directory does not exist: $HOST_VOLUME"
        fi
    fi
    
    # Build GPU arguments
    GPU_ARGS=$(build_gpu_args)
    
    # Set environment variables
    ENV_VARS=""
    if [ "$FORCE_CUDA126" = true ]; then
        ENV_VARS="$ENV_VARS -e FORCE_CUDA126=true"
        echo "üîß NVIDIA Universal mode enabled (CUDA 12.6)"
    fi
    
    # Check if container already exists and is stopped
    if docker ps -a --format '{{.Names}}' | grep -q "^${CONTAINER_NAME}$"; then
        if is_container_running; then
            echo "‚úÖ Container '$CONTAINER_NAME' is already running"
            echo ""
            echo "üí° Use these commands:"
            echo "   $0 exec launch --background    # Start ComfyUI"
            echo "   $0 shell                       # Open shell"
            echo "   $0 status                      # Check status"
            return
        else
            echo "‚ö†Ô∏è Container '$CONTAINER_NAME' exists but is stopped"
            read -p "Start it? (Y/n): " response
            if [[ "$response" =~ ^[Yy]$ ]] || [[ -z "$response" ]]; then
                echo "Starting existing container..."
                docker start -ai "$CONTAINER_NAME"
                return
            else
                echo "Removing old container..."
                docker rm "$CONTAINER_NAME" 2>/dev/null
            fi
        fi
    fi
    
    echo "üìã Container configuration:"
    echo "   Name: $CONTAINER_NAME"
    echo "   Port: $HOST_PORT:$CONTAINER_PORT"
    echo "   GPU: $( [ "$USE_GPU" = true ] && echo "Enabled" || echo "Disabled" )"
    echo "   NVIDIA Universal: $( [ "$FORCE_CUDA126" = true ] && echo "Enabled (CUDA 12.6)" || echo "Disabled" )"
    echo "   Volume: $DATA_VOLUME"
    [ -n "$HOST_VOLUME" ] && echo "   Host Volume: $HOST_VOLUME"
    echo ""
    
    # Create data volume if it doesn't exist
    if ! docker volume inspect "$DATA_VOLUME" &> /dev/null; then
        echo "üìÅ Creating data volume: $DATA_VOLUME"
        docker volume create "$DATA_VOLUME"
    fi
    
    echo "üê≥ Starting Docker container..."
    echo "üí° This will set up ComfyUI (first time only)"
    echo "   After setup, use '$0 exec' to run comfy-cli commands"
    echo ""
    
    # Run the container
    docker run -it --rm \
        --name "$CONTAINER_NAME" \
        -p "$HOST_PORT:$CONTAINER_PORT" \
        $GPU_ARGS \
        $VOLUME_MOUNTS \
        -e HOST_UID=$(id -u) \
        -e HOST_GID=$(id -g) \
        -e HOST_PORT="$HOST_PORT" \
        -e CONTAINER_NAME="$CONTAINER_NAME" \
        -e FORCE_CUDA126="$FORCE_CUDA126" \
        -e NVIDIA_VISIBLE_DEVICES=all \
        -e NVIDIA_DRIVER_CAPABILITIES=compute,utility,graphics \
        $ENV_VARS \
        "$IMAGE_NAME"
}

# Open shell in container
shell_container() {
    if is_container_running; then
        echo "üìÇ Opening shell in running container..."
        docker exec -it "$CONTAINER_NAME" /bin/bash
    else
        echo "‚ö†Ô∏è Container '$CONTAINER_NAME' is not running"
        read -p "Start it first? (Y/n): " response
        if [[ "$response" =~ ^[Yy]$ ]] || [[ -z "$response" ]]; then
            run_container
        fi
    fi
}

# Stop container
stop_container() {
    echo "üõë Stopping container..."
    if docker stop "$CONTAINER_NAME" 2>/dev/null; then
        echo "‚úÖ Container stopped"
    else
        echo "‚ö†Ô∏è Container not running or doesn't exist"
    fi
}

# View logs
view_logs() {
    if docker ps -a --format '{{.Names}}' | grep -q "^${CONTAINER_NAME}$"; then
        echo "üìã Container logs:"
        docker logs "$CONTAINER_NAME"
    else
        echo "‚ö†Ô∏è Container '$CONTAINER_NAME' does not exist"
    fi
}

# Clean up (remove container and image, keep volume)
cleanup() {
    echo "üßπ Cleaning up Docker resources..."
    
    # Stop and remove container
    docker stop "$CONTAINER_NAME" 2>/dev/null
    docker rm "$CONTAINER_NAME" 2>/dev/null 2>&1
    
    # Remove image
    if docker image inspect "$IMAGE_NAME" &> /dev/null; then
        docker rmi "$IMAGE_NAME" && echo "‚úÖ Image removed"
    else
        echo "‚ÑπÔ∏è  Image not found"
    fi
    
    # Clean up Docker context
    rm -rf "$DOCKER_CONTEXT" 2>&1
    
    echo "üìÅ Data volume '${DATA_VOLUME}' preserved"
}

# Purge everything including volume
purge_all() {
    echo "üî• Purging all Docker resources..."
    
    # Stop and remove container
    docker stop "$CONTAINER_NAME" 2>/dev/null
    docker rm "$CONTAINER_NAME" 2>/dev/null 2>&1
    
    # Remove image
    docker rmi "$IMAGE_NAME" 2>/dev/null 2>&1
    
    # Remove volume
    if docker volume inspect "$DATA_VOLUME" &> /dev/null; then
        docker volume rm "$DATA_VOLUME" && echo "‚úÖ Data volume removed"
    else
        echo "‚ÑπÔ∏è  Data volume not found"
    fi
    
    # Clean up Docker context
    rm -rf "$DOCKER_CONTEXT" 2>&1
    
    echo "‚úÖ All resources purged"
}

# Main execution
main() {
    # Show help if requested
    if [[ "$1" == "-h" ]] || [[ "$1" == "--help" ]]; then
        show_help
    fi
    
    parse_arguments "$@"
    
    case "$COMMAND" in
        run)
            run_container
            ;;
        build)
            build_image
            ;;
        shell)
            shell_container
            ;;
        stop)
            stop_container
            ;;
        logs)
            view_logs
            ;;
        status)
            show_status
            ;;
        exec)
            exec_comfy_cli
            ;;
        clean)
            cleanup
            ;;
        purge)
            purge_all
            ;;
        help)
            show_help
            ;;
        *)
            echo "‚ùå Unknown command: $COMMAND"
            show_help
            ;;
    esac
}

# Run main function
main "$@"