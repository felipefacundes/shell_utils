#!/usr/bin/env bash
# License: GPLv3
# Credits: Felipe Facundes
# Source: https://github.com/comfyanonymous/ComfyUI
# Tutorial: https://www.youtube.com/watch?v=TLE9NmN_sxw
#           https://youtu.be/xWUddF5oMb0
# Docker version for Python 3.13

# Function to display help menu
show_help() {
    cat << EOF

‚ïî‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïó
‚ïë                  COMFY-CLI DOCKER SCRIPT (Python 3.13)           ‚ïë
‚ïë                     Containerized Installation                    ‚ïë
‚ïö‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïê‚ïù

DESCRIPTION:
    This script creates and manages a Docker container for ComfyUI CLI
    with Python 3.13, automatic GPU detection, and persistent storage.

INSTALLATION LOCATIONS:
    ‚Ä¢ Docker Volume (default): comfy-cli-data
    ‚Ä¢ Host Directory: Use --data-dir to specify custom location
    ‚Ä¢ Inside Container: /app/

USAGE:
    $0 [COMMAND] [OPTIONS]

COMMANDS:
    run         Start ComfyUI CLI in Docker container (default if no command)
    build       Build Docker image with Python 3.13
    shell       Open interactive shell in container
    stop        Stop running container
    logs        View container logs
    clean       Remove container and images (keeps data volume)
    purge       Remove everything including data volume
    path        Show where data is stored
    help        Show this help message

OPTIONS for 'run' command:
    -g, --gpu          Use GPU acceleration (NVIDIA/AMD)
    -p, --port PORT    Map container port to host (default: 8188)
    -n, --name NAME    Container name (default: comfy-cli)
    -d, --data-dir DIR Use host directory instead of Docker volume
    -v, --volume DIR   Mount additional host directory as /app/shared
    -nu, --nvidia-universal  Force CUDA 12.6 for NVIDIA (compatibility mode)

EXAMPLES:
    # Run with GPU support and CUDA 12.6 (uses Docker volume)
    $0 run --gpu -nu
    
    # Run with custom data directory on host
    $0 run --gpu --data-dir ~/comfy-data
    
    # Run with custom port and additional volume
    $0 run --port 8080 --volume ./models:/app/models
    
    # Show where data is stored
    $0 path
    
    # Build the Docker image
    $0 build

DATA LOCATIONS:
    ‚îå‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¨‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îê
    ‚îÇ Location Type        ‚îÇ Path                                    ‚îÇ
    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
    ‚îÇ Docker Volume        ‚îÇ comfy-cli-data                          ‚îÇ
    ‚îÇ                      ‚îÇ (Host: /var/lib/docker/volumes/...)     ‚îÇ
    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
    ‚îÇ Host Directory       ‚îÇ User specified with --data-dir          ‚îÇ
    ‚îú‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îº‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î§
    ‚îÇ Inside Container     ‚îÇ /app/                                   ‚îÇ
    ‚îî‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚î¥‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îÄ‚îò

CONTAINER STRUCTURE:
    /app/
    ‚îú‚îÄ‚îÄ comfy-ui/          # ComfyUI installation
    ‚îú‚îÄ‚îÄ models/            # AI models (recommended to mount)
    ‚îú‚îÄ‚îÄ output/            # Generated images/outputs
    ‚îú‚îÄ‚îÄ config/            # Configuration files
    ‚îî‚îÄ‚îÄ shared/            # Additional mounted volumes

EOF
    exit 0
}

# Default configuration
CONTAINER_NAME="comfy-cli"
IMAGE_NAME="comfy-cli-python3.13"
DATA_VOLUME="comfy-cli-data"
HOST_PORT="8188"
CONTAINER_PORT="8188"
USE_GPU=false
HOST_VOLUME=""
HOST_DATA_DIR=""
FORCE_CUDA126=false
SCRIPT_DIR="$(cd "$(dirname "${BASH_SOURCE[0]}")" && pwd)"
DOCKER_CONTEXT="${SCRIPT_DIR}/docker-context"

# Parse command line arguments
parse_arguments() {
    COMMAND="${1:-run}"
    
    case "$COMMAND" in
        run|build|shell|stop|logs|clean|purge|path|help)
            shift
            ;;
        *)
            COMMAND="run"
            ;;
    esac
    
    while [[ $# -gt 0 ]]; do
        case "$1" in
            -g|--gpu)
                USE_GPU=true
                shift
                ;;
            -nu|--nvidia-universal)
                FORCE_CUDA126=true
                shift
                ;;
            -p|--port)
                HOST_PORT="$2"
                shift 2
                ;;
            -n|--name)
                CONTAINER_NAME="$2"
                shift 2
                ;;
            -d|--data-dir)
                HOST_DATA_DIR="$2"
                shift 2
                ;;
            -v|--volume)
                HOST_VOLUME="$2"
                shift 2
                ;;
            -h|--help)
                show_help
                ;;
            *)
                echo "‚ö†Ô∏è Unknown option: $1"
                show_help
                ;;
        esac
    done
}

# Show data path
show_data_path() {
    echo "üìÅ Data Storage Locations"
    echo "========================"
    
    # Check Docker volume
    if docker volume inspect "$DATA_VOLUME" &> /dev/null; then
        echo "‚úÖ Docker Volume: $DATA_VOLUME"
        VOLUME_PATH=$(docker volume inspect "$DATA_VOLUME" | grep "Mountpoint" | cut -d'"' -f4)
        echo "   Host Path: $VOLUME_PATH"
        echo "   Container Path: /app/"
    else
        echo "‚ö†Ô∏è Docker volume '$DATA_VOLUME' not created yet"
    fi
    
    # Check if running with host directory
    if [ -n "$HOST_DATA_DIR" ] && [ -d "$HOST_DATA_DIR" ]; then
        echo ""
        echo "‚úÖ Host Directory:"
        echo "   Host Path: $(realpath "$HOST_DATA_DIR")"
        echo "   Container Path: /app/"
    fi
    
    # Show running container info
    if docker ps --format '{{.Names}}' | grep -q "^${CONTAINER_NAME}$"; then
        echo ""
        echo "üì¶ Running Container: $CONTAINER_NAME"
        echo "   Port: $(docker port "$CONTAINER_NAME" | grep "$CONTAINER_PORT")"
        echo "   Status: $(docker ps --filter "name=$CONTAINER_NAME" --format "{{.Status}}")"
    fi
    
    echo ""
    echo "üí° To access data:"
    echo "   docker exec -it $CONTAINER_NAME ls -la /app/"
    echo "   docker exec -it $CONTAINER_NAME /bin/bash"
}

# Create Docker context directory
create_docker_context() {
    echo "üìÅ Creating Docker build context..."
    
    # Create directory
    rm -rf "$DOCKER_CONTEXT"
    mkdir -p "$DOCKER_CONTEXT"
    
    # Create Dockerfile
    cat > "$DOCKER_CONTEXT/Dockerfile" << 'EOF'
FROM python:3.13-slim

WORKDIR /app

# Install system dependencies for Debian Trixie/Sid
RUN apt-get update && apt-get install -y \
    wget \
    curl \
    git \
    libglib2.0-0 \
    libsm6 \
    libxext6 \
    libxrender1 \
    libgl1 \
    libgomp1 \
    ocl-icd-libopencl1 \
    clinfo \
    pciutils \
    libglvnd0 \
    libglx0 \
    libegl1 \
    && rm -rf /var/lib/apt/lists/*

# For NVIDIA GPU support in container
RUN apt-get update && apt-get install -y --no-install-recommends \
    pkg-config \
    libxcursor-dev \
    libxrandr-dev \
    libxinerama-dev \
    libxi-dev \
    && rm -rf /var/lib/apt/lists/*

# Create directory structure
RUN mkdir -p /app/comfy-ui /app/models /app/output /app/config /app/shared

# Copy scripts
COPY scripts/ /app/

# Set permissions
RUN chmod +x /app/*.sh

# Set environment variables
ENV PYTHONUNBUFFERED=1
ENV PYTHONDONTWRITEBYTECODE=1
ENV PIP_NO_CACHE_DIR=1
ENV COMFYUI_PATH=/app/comfy-ui
ENV MODEL_PATH=/app/models
ENV OUTPUT_PATH=/app/output
ENV CONFIG_PATH=/app/config
ENV SHARED_PATH=/app/shared
ENV HOST_PORT=8188
ENV CONTAINER_NAME=comfy-cli
ENV FORCE_CUDA126=false
ENV DEBIAN_FRONTEND=noninteractive

# Set entrypoint
ENTRYPOINT ["/app/entrypoint.sh"]
CMD []
EOF
    
    # Create scripts directory
    mkdir -p "$DOCKER_CONTEXT/scripts"
    
    # Create detect_gpu.sh
    cat > "$DOCKER_CONTEXT/scripts/detect_gpu.sh" << 'SCRIPT_EOF'
#!/bin/bash

FORCE_CUDA126="${FORCE_CUDA126:-false}"

detect_and_install_pytorch() {
    echo "üîç Detecting GPU hardware..."
    
    # Check for NVIDIA GPU
    if command -v nvidia-smi &> /dev/null && nvidia-smi > /dev/null 2>&1; then
        echo "‚úÖ NVIDIA GPU detected"
        
        # NVIDIA Universal mode (force CUDA 12.6)
        if [ "$FORCE_CUDA126" = "true" ]; then
            echo "üîß Using NVIDIA Universal mode (CUDA 12.6)"
            echo "‚¨áÔ∏è Installing PyTorch 2.9.0 with CUDA 12.6"
            pip install torch==2.9.0 torchvision==0.24.0 torchaudio==2.9.0 \
                --index-url https://download.pytorch.org/whl/cu126
            return
        fi
        
        # Auto-detect CUDA version based on driver
        if command -v nvidia-smi &> /dev/null; then
            DRIVER_VERSION=$(nvidia-smi --query-gpu=driver_version --format=csv,noheader | head -1)
            echo "üìä NVIDIA Driver version: $DRIVER_VERSION"
            
            # Extract major version
            DRIVER_MAJOR=$(echo "$DRIVER_VERSION" | cut -d. -f1)
            
            if [ "$DRIVER_MAJOR" -ge 535 ]; then  # Driver 535+
                echo "‚¨áÔ∏è Installing PyTorch with CUDA 12.6 (latest)"
                pip install torch==2.9.0 torchvision==0.24.0 torchaudio==2.9.0 \
                    --index-url https://download.pytorch.org/whl/cu126
            elif [ "$DRIVER_MAJOR" -ge 525 ]; then  # Driver 525-534
                echo "‚¨áÔ∏è Installing PyTorch with CUDA 11.8"
                pip install torch==2.9.0 torchvision==0.24.0 torchaudio==2.9.0 \
                    --index-url https://download.pytorch.org/whl/cu118
            elif [ "$DRIVER_MAJOR" -ge 470 ]; then  # Driver 470-524
                echo "‚¨áÔ∏è Installing PyTorch with CUDA 11.3"
                pip install torch==2.9.0 torchvision==0.24.0 torchaudio==2.9.0 \
                    --index-url https://download.pytorch.org/whl/cu113
            else
                echo "‚ö†Ô∏è Old NVIDIA driver, using CUDA 12.6 as fallback"
                pip install torch==2.9.0 torchvision==0.24.0 torchaudio==2.9.0 \
                    --index-url https://download.pytorch.org/whl/cu126
            fi
        else
            echo "‚¨áÔ∏è Installing PyTorch with CUDA 12.6 (auto-fallback)"
            pip install torch==2.9.0 torchvision==0.24.0 torchaudio==2.9.0 \
                --index-url https://download.pytorch.org/whl/cu126
        fi
        
    # Check for AMD GPU (ROCm)
    elif [[ -d "/dev/dri" ]] && lspci | grep -i "amd" | grep -i "vga" &> /dev/null; then
        echo "‚úÖ AMD GPU detected (ROCm)"
        echo "‚¨áÔ∏è Installing PyTorch with ROCm 6.4"
        pip install torch==2.9.0 torchvision==0.24.0 torchaudio==2.9.0 \
            --index-url https://download.pytorch.org/whl/rocm6.4
    
    # Check for Intel GPU
    elif lspci | grep -i "intel" | grep -i "vga" &> /dev/null; then
        echo "‚úÖ Intel GPU detected"
        echo "‚¨áÔ∏è Installing PyTorch with XPU"
        pip install torch==2.9.0 torchvision==0.24.0 torchaudio==2.9.0 \
            --index-url https://download.pytorch.org/whl/xpu
    
    else
        echo "‚ö†Ô∏è No GPU detected - installing CPU version"
        pip install torch==2.9.0 torchvision==0.24.0 torchaudio==2.9.0
    fi
}

detect_and_install_pytorch
SCRIPT_EOF
    
    # Create setup_comfy.sh
    cat > "$DOCKER_CONTEXT/scripts/setup_comfy.sh" << 'SCRIPT_EOF'
#!/bin/bash

# Set FORCE_CUDA126 from environment variable
export FORCE_CUDA126="${FORCE_CUDA126:-false}"

echo "üîß Configuration:"
echo "   - FORCE_CUDA126: $FORCE_CUDA126"
echo "   - NVIDIA Universal mode: $( [ "$FORCE_CUDA126" = "true" ] && echo "ENABLED" || echo "DISABLED" )"

# Source GPU detection script
source /app/detect_gpu.sh

echo "üì¶ Installing ComfyUI requirements..."
cd /app/comfy-ui

# Download requirements if not present
if [ ! -f "requirements.txt" ]; then
    echo "‚¨áÔ∏è Downloading ComfyUI requirements..."
    wget -q https://raw.githubusercontent.com/comfyanonymous/ComfyUI/refs/heads/master/requirements.txt || \
    curl -s -o requirements.txt https://raw.githubusercontent.com/comfyanonymous/ComfyUI/refs/heads/master/requirements.txt
fi

# Install requirements
if [ -f "requirements.txt" ]; then
    echo "üì• Installing from requirements.txt..."
    pip install -r requirements.txt
else
    echo "‚ö†Ô∏è requirements.txt not found, installing basic packages..."
fi

# Install comfy-cli
echo "üì¶ Installing comfy-cli..."
pip install comfy-cli

# Install additional useful packages
echo "üì¶ Installing additional packages..."
pip install --upgrade pip
pip install \
    pillow \
    numpy \
    scipy \
    pandas \
    matplotlib \
    opencv-python-headless \
    transformers \
    accelerate \
    safetensors \
    websockets \
    aiohttp \
    torchsde \
    kornia \
    rich

echo "‚úÖ ComfyUI setup complete!"
echo "üìä Installed PyTorch version: $(python -c "import torch; print(torch.__version__)")"
if command -v nvidia-smi &> /dev/null; then
    echo "üéÆ Checking CUDA availability..."
    python -c "
import torch
print(f'CUDA available: {torch.cuda.is_available()}')
if torch.cuda.is_available():
    print(f'CUDA version: {torch.version.cuda}')
    print(f'GPU: {torch.cuda.get_device_name(0)}')
    print(f'GPU Memory: {torch.cuda.get_device_properties(0).total_memory / 1024**3:.2f} GB')
"
fi

# Show directory structure
echo ""
echo "üìÅ Directory structure in /app/:"
ls -la /app/
echo ""
echo "üíæ Data locations:"
echo "   ComfyUI: /app/comfy-ui"
echo "   Models:  /app/models"
echo "   Output:  /app/output"
echo "   Config:  /app/config"
echo "   Shared:  /app/shared"
SCRIPT_EOF
    
    # Create entrypoint.sh
    cat > "$DOCKER_CONTEXT/scripts/entrypoint.sh" << 'SCRIPT_EOF'
#!/bin/bash

# Export environment variables for GPU detection
export FORCE_CUDA126="${FORCE_CUDA126:-false}"

echo "üöÄ Starting ComfyUI Docker Container"
echo "===================================="
echo "Python version: $(python --version)"
echo "FORCE_CUDA126: $FORCE_CUDA126"
echo "Working directory: $(pwd)"
echo "Data location: /app/"
echo ""

# Check for GPU
echo "üîç Checking system configuration..."
if command -v nvidia-smi &> /dev/null; then
    echo "‚úÖ NVIDIA GPU detected in container"
    nvidia-smi --query-gpu=name,driver_version --format=csv
elif [[ -d "/dev/dri" ]]; then
    echo "‚úÖ AMD/Intel GPU detected (OpenGL available)"
else
    echo "‚ÑπÔ∏è  Running in CPU mode"
fi
echo ""

# Initialize ComfyUI if not already done
if [ ! -d "/app/comfy-ui" ] || [ ! "$(ls -A /app/comfy-ui)" ]; then
    echo "üîÑ Initializing ComfyUI for the first time..."
    comfy-cli install /app/comfy-ui --force
    echo "‚úÖ ComfyUI installed to /app/comfy-ui"
else
    echo "‚úÖ ComfyUI already installed in /app/comfy-ui"
fi

# Run setup script
source /app/setup_comfy.sh

echo ""
echo "‚úÖ Environment ready!"
echo "üåê Web UI accessible at: http://localhost:${HOST_PORT:-8188}"
echo "üíæ Data stored in: /app/"
echo "üí° Use 'docker exec -it ${CONTAINER_NAME:-comfy-cli} /bin/bash' for shell access"
echo ""

# Execute passed command or start comfy-cli
if [ $# -gt 0 ]; then
    echo "‚ö° Executing: $@"
    exec "$@"
else
    echo "‚ö° Starting ComfyUI CLI..."
    exec comfy-cli "$@"
fi
SCRIPT_EOF
    
    echo "‚úÖ Docker context created at: $DOCKER_CONTEXT"
}

# Build Docker image with Python 3.13
build_image() {
    echo "üöÄ Building Docker image with Python 3.13..."
    
    # Create Docker context
    create_docker_context
    
    # Build the Docker image
    echo "üî® Building image '$IMAGE_NAME'..."
    if docker build --progress=plain -t "$IMAGE_NAME" "$DOCKER_CONTEXT"; then
        echo "‚úÖ Docker image built successfully: $IMAGE_NAME"
        echo "üì¶ Image includes:"
        echo "   ‚Ä¢ Python 3.13"
        echo "   ‚Ä¢ NVIDIA Universal mode support (-nu flag)"
        echo "   ‚Ä¢ Automatic GPU detection"
        echo "   ‚Ä¢ ComfyUI CLI pre-configured"
        
        # Show image details
        echo ""
        echo "üìä Image details:"
        docker images "$IMAGE_NAME"
    else
        echo "‚ùå Failed to build Docker image"
        exit 1
    fi
}

# Build volume mounts based on configuration
build_volume_mounts() {
    local mounts=""
    
    # Use host directory if specified
    if [ -n "$HOST_DATA_DIR" ]; then
        # Create directory if it doesn't exist
        mkdir -p "$HOST_DATA_DIR"
        mounts="-v $(realpath "$HOST_DATA_DIR"):/app"
        echo "üìÇ Using host directory: $HOST_DATA_DIR ‚Üí /app"
    else
        # Use Docker volume
        if ! docker volume inspect "$DATA_VOLUME" &> /dev/null; then
            echo "üìÅ Creating Docker volume: $DATA_VOLUME"
            docker volume create "$DATA_VOLUME"
        fi
        mounts="-v ${DATA_VOLUME}:/app"
        echo "üìÇ Using Docker volume: $DATA_VOLUME ‚Üí /app"
    fi
    
    # Add additional volumes if specified
    if [ -n "$HOST_VOLUME" ]; then
        if [ -d "$HOST_VOLUME" ]; then
            mounts="$mounts -v $(realpath "$HOST_VOLUME"):/app/shared"
            echo "üìÇ Mounting additional volume: $HOST_VOLUME ‚Üí /app/shared"
        else
            echo "‚ö†Ô∏è Additional volume directory does not exist: $HOST_VOLUME"
        fi
    fi
    
    echo "$mounts"
}

# Build GPU arguments for docker run
build_gpu_args() {
    if [ "$USE_GPU" = true ]; then
        # Check for NVIDIA
        if command -v nvidia-smi &> /dev/null; then
            echo "--gpus all"
        # Check for AMD (simplified detection)
        elif [ -d "/dev/dri" ] && [ -d "/dev/kfd" ]; then
            echo "--device /dev/kfd --device /dev/dri --group-add video"
        # Check for Intel
        elif [ -d "/dev/dri" ]; then
            echo "--device /dev/dri --group-add video"
        else
            echo "‚ö†Ô∏è GPU flag set but no GPU detected, running in CPU mode"
            echo ""
        fi
    else
        echo ""
    fi
}

# Run container
run_container() {
    echo "üöÄ Starting ComfyUI container..."
    
    # Check if image exists
    if ! docker image inspect "$IMAGE_NAME" &> /dev/null; then
        echo "‚ö†Ô∏è Image not found. Building first..."
        build_image
    fi
    
    # Build volume mounts
    VOLUME_MOUNTS=$(build_volume_mounts)
    
    # Build GPU arguments
    GPU_ARGS=$(build_gpu_args)
    
    # Set environment variables
    ENV_VARS=""
    if [ "$FORCE_CUDA126" = true ]; then
        ENV_VARS="$ENV_VARS -e FORCE_CUDA126=true"
        echo "üîß NVIDIA Universal mode enabled (CUDA 12.6)"
    fi
    
    # Check if container already exists
    if docker ps -a --format '{{.Names}}' | grep -q "^${CONTAINER_NAME}$"; then
        echo "‚ö†Ô∏è Container '$CONTAINER_NAME' already exists"
        read -p "Stop and remove it? (y/N): " response
        if [[ "$response" =~ ^[Yy]$ ]]; then
            docker stop "$CONTAINER_NAME" 2>/dev/null
            docker rm "$CONTAINER_NAME" 2>/dev/null
            echo "‚úÖ Container removed"
        else
            echo "Starting existing container..."
            # Update environment if needed
            if [ "$FORCE_CUDA126" = true ]; then
                echo "‚ö†Ô∏è Note: FORCE_CUDA126 requires container restart to take effect"
            fi
            docker start -ai "$CONTAINER_NAME"
            return
        fi
    fi
    
    echo "üìã Container configuration:"
    echo "   Name: $CONTAINER_NAME"
    echo "   Port: $HOST_PORT:$CONTAINER_PORT"
    echo "   GPU: $( [ "$USE_GPU" = true ] && echo "Enabled" || echo "Disabled" )"
    echo "   NVIDIA Universal: $( [ "$FORCE_CUDA126" = true ] && echo "Enabled (CUDA 12.6)" || echo "Disabled" )"
    if [ -n "$HOST_DATA_DIR" ]; then
        echo "   Data: Host directory: $(realpath "$HOST_DATA_DIR")"
    else
        echo "   Data: Docker volume: $DATA_VOLUME"
    fi
    [ -n "$HOST_VOLUME" ] && echo "   Additional Volume: $HOST_VOLUME ‚Üí /app/shared"
    echo ""
    
    # Run the container
    echo "üê≥ Starting Docker container..."
    docker run -it --rm \
        --name "$CONTAINER_NAME" \
        -p "$HOST_PORT:$CONTAINER_PORT" \
        $GPU_ARGS \
        $VOLUME_MOUNTS \
        -e HOST_UID=$(id -u) \
        -e HOST_GID=$(id -g) \
        -e HOST_PORT="$HOST_PORT" \
        -e CONTAINER_NAME="$CONTAINER_NAME" \
        -e FORCE_CUDA126="$FORCE_CUDA126" \
        -e NVIDIA_VISIBLE_DEVICES=all \
        -e NVIDIA_DRIVER_CAPABILITIES=compute,utility,graphics \
        $ENV_VARS \
        "$IMAGE_NAME"
}

# Open shell in container
shell_container() {
    if docker ps --format '{{.Names}}' | grep -q "^${CONTAINER_NAME}$"; then
        echo "üìÇ Opening shell in running container..."
        docker exec -it "$CONTAINER_NAME" /bin/bash
    else
        echo "‚ö†Ô∏è Container '$CONTAINER_NAME' is not running"
        read -p "Start it first? (y/N): " response
        if [[ "$response" =~ ^[Yy]$ ]]; then
            run_container
        fi
    fi
}

# Stop container
stop_container() {
    echo "üõë Stopping container..."
    if docker stop "$CONTAINER_NAME" 2>/dev/null; then
        echo "‚úÖ Container stopped"
    else
        echo "‚ö†Ô∏è Container not running or doesn't exist"
    fi
}

# View logs
view_logs() {
    if docker ps -a --format '{{.Names}}' | grep -q "^${CONTAINER_NAME}$"; then
        echo "üìã Container logs:"
        docker logs "$CONTAINER_NAME"
    else
        echo "‚ö†Ô∏è Container '$CONTAINER_NAME' does not exist"
    fi
}

# Clean up (remove container and image, keep volume)
cleanup() {
    echo "üßπ Cleaning up Docker resources..."
    
    # Stop and remove container
    docker stop "$CONTAINER_NAME" 2>/dev/null
    docker rm "$CONTAINER_NAME" 2>/dev/null 2>&1
    
    # Remove image
    if docker image inspect "$IMAGE_NAME" &> /dev/null; then
        docker rmi "$IMAGE_NAME" && echo "‚úÖ Image removed"
    else
        echo "‚ÑπÔ∏è  Image not found"
    fi
    
    # Clean up Docker context
    rm -rf "$DOCKER_CONTEXT" 2>&1
    
    # Don't remove data volume/directory
    if [ -n "$HOST_DATA_DIR" ]; then
        echo "üìÅ Host data directory preserved: $(realpath "$HOST_DATA_DIR")"
    else
        echo "üìÅ Docker volume preserved: $DATA_VOLUME"
    fi
}

# Purge everything including volume
purge_all() {
    echo "üî• Purging all Docker resources..."
    
    # Stop and remove container
    docker stop "$CONTAINER_NAME" 2>/dev/null
    docker rm "$CONTAINER_NAME" 2>/dev/null 2>&1
    
    # Remove image
    docker rmi "$IMAGE_NAME" 2>/dev/null 2>&1
    
    # Remove Docker volume (if not using host directory)
    if [ -z "$HOST_DATA_DIR" ]; then
        if docker volume inspect "$DATA_VOLUME" &> /dev/null; then
            docker volume rm "$DATA_VOLUME" && echo "‚úÖ Data volume removed"
        else
            echo "‚ÑπÔ∏è  Data volume not found"
        fi
    else
        echo "‚ö†Ô∏è Host directory NOT removed: $(realpath "$HOST_DATA_DIR")"
        read -p "Remove host directory? (y/N): " response
        if [[ "$response" =~ ^[Yy]$ ]]; then
            rm -rf "$HOST_DATA_DIR" && echo "‚úÖ Host directory removed"
        fi
    fi
    
    # Clean up Docker context
    rm -rf "$DOCKER_CONTEXT" 2>&1
    
    echo "‚úÖ All Docker resources purged"
}

# Main execution
main() {
    # Show help if requested
    if [[ "$1" == "-h" ]] || [[ "$1" == "--help" ]]; then
        show_help
    fi
    
    # Special command to show data path
    if [[ "$1" == "path" ]]; then
        show_data_path
        exit 0
    fi
    
    parse_arguments "$@"
    
    case "$COMMAND" in
        run)
            run_container
            ;;
        build)
            build_image
            ;;
        shell)
            shell_container
            ;;
        stop)
            stop_container
            ;;
        logs)
            view_logs
            ;;
        clean)
            cleanup
            ;;
        purge)
            purge_all
            ;;
        path)
            show_data_path
            ;;
        help)
            show_help
            ;;
        *)
            echo "‚ùå Unknown command: $COMMAND"
            show_help
            ;;
    esac
}

# Run main function
main "$@"